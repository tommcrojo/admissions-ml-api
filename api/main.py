"""API REST para inferencia usando datos preprocesados.

Este módulo proporciona endpoints para predecir la probabilidad de admisión
basándose en características ya preprocesadas por el pipeline de PySpark.

Los datos de entrada deben tener el mismo formato que gold.ml_features.
"""

from typing import Dict, Any, Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
import joblib
import numpy as np
import uvicorn
import os

app = FastAPI(
    title="Admissions Inference API",
    description="ML inference service using preprocessed features",
    version="2.0.0",
)

model = joblib.load("models/rf_model.pkl")


class PreprocessedFeatures(BaseModel):
    nota_normalizada: float = Field(..., ge=0, le=1)
    edad: int = Field(..., ge=16, le=80)
    creditos_ratio: float = Field(..., ge=0)
    rama_ciencias: int = Field(..., ge=0, le=1)
    rama_sociales: int = Field(..., ge=0, le=1)
    rama_ingenieria: int = Field(..., ge=0, le=1)
    es_murcia: int = Field(..., ge=0, le=1)
    es_extranjero: int = Field(..., ge=0, le=1)
    es_online: int = Field(..., ge=0, le=1)

    class Config:
        schema_extra = {
            "example": {
                "nota_normalizada": 0.7,
                "edad": 22,
                "creditos_ratio": 1.0,
                "rama_ciencias": 1,
                "rama_sociales": 0,
                "rama_ingenieria": 0,
                "es_murcia": 1,
                "es_extranjero": 0,
                "es_online": 0,
            }
        }


class PredictionOutput(BaseModel):
    prediction: str
    probability: float
    confidence: str
    model_version: str = "2.0.0"


@app.get("/")
def root() -> Dict[str, str]:
    return {
        "message": "Admissions Inference API",
        "status": "active",
        "version": "2.0.0",
    }


@app.get("/health")
def health_check() -> Dict[str, Any]:
    return {"status": "healthy", "model_loaded": model is not None}


@app.post("/predict", response_model=PredictionOutput)
def predict(features: PreprocessedFeatures) -> PredictionOutput:
    """Predict admission probability using preprocessed features.

    Args:
        features: Preprocessed features matching gold.ml_features schema.
                  These should be generated by the PySpark preprocessing pipeline.

    Returns:
        PredictionOutput with prediction, probability, and confidence.

    Raises:
        HTTPException: Si ocurre un error durante la predicción.
    """
    try:
        features_array = np.array(
            [
                [
                    features.nota_normalizada,
                    features.edad,
                    features.creditos_ratio,
                    features.rama_ciencias,
                    features.rama_sociales,
                    features.rama_ingenieria,
                    features.es_murcia,
                    features.es_extranjero,
                    features.es_online,
                ]
            ],
            dtype=np.float64,
        )

        proba = model.predict_proba(features_array)[0]
        prob_admitido = float(proba[1]) if len(proba) > 1 else float(proba[0])

        prediction = "admitido" if prob_admitido >= 0.5 else "rechazado"
        confidence = (
            "high"
            if prob_admitido >= 0.8 or prob_admitido <= 0.2
            else "medium"
            if prob_admitido >= 0.65 or prob_admitido <= 0.35
            else "low"
        )

        return PredictionOutput(
            prediction=prediction,
            probability=round(prob_admitido, 3),
            confidence=confidence,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error en predicción: {str(e)}")


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
